{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMq4n+Qz4hOrBSigd9yBmig",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anjalii-s/Thesis-2026-/blob/main/Taiwan_statistical_validations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjjKsIK5sHQG",
        "outputId": "29f26987-161f-44cd-d1b1-5e20a2083b8a"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/uciml/default-of-credit-card-clients-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 0.98M/0.98M [00:00<00:00, 18.9MB/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 | RF+None         → AUC: 0.7891\n",
            "Fold 2 | RF+None         → AUC: 0.7756\n",
            "Fold 3 | RF+None         → AUC: 0.7834\n",
            "Fold 4 | RF+None         → AUC: 0.7724\n",
            "Fold 1 | RF+SMOTE        → AUC: 0.7830\n",
            "Fold 2 | RF+SMOTE        → AUC: 0.7665\n",
            "Fold 3 | RF+SMOTE        → AUC: 0.7783\n",
            "Fold 4 | RF+SMOTE        → AUC: 0.7707\n",
            "Fold 1 | RF+Borderline   → AUC: 0.7805\n",
            "Fold 2 | RF+Borderline   → AUC: 0.7636\n",
            "Fold 3 | RF+Borderline   → AUC: 0.7758\n",
            "Fold 4 | RF+Borderline   → AUC: 0.7689\n",
            "Fold 1 | RF+ADASYN       → AUC: 0.7794\n",
            "Fold 2 | RF+ADASYN       → AUC: 0.7630\n",
            "Fold 3 | RF+ADASYN       → AUC: 0.7773\n",
            "Fold 4 | RF+ADASYN       → AUC: 0.7676\n",
            "Fold 1 | RF+SMOTEENN     → AUC: 0.7836\n",
            "Fold 2 | RF+SMOTEENN     → AUC: 0.7662\n",
            "Fold 3 | RF+SMOTEENN     → AUC: 0.7793\n",
            "Fold 4 | RF+SMOTEENN     → AUC: 0.7708\n",
            "Fold 1 | RF+SMOTETomek   → AUC: 0.7824\n",
            "Fold 2 | RF+SMOTETomek   → AUC: 0.7668\n",
            "Fold 3 | RF+SMOTETomek   → AUC: 0.7807\n",
            "Fold 4 | RF+SMOTETomek   → AUC: 0.7715\n",
            "Fold 1 | RF+Under        → AUC: 0.7876\n",
            "Fold 2 | RF+Under        → AUC: 0.7734\n",
            "Fold 3 | RF+Under        → AUC: 0.7827\n",
            "Fold 4 | RF+Under        → AUC: 0.7744\n",
            "Fold 1 | RF+CostSensitive → AUC: 0.7876\n",
            "Fold 2 | RF+CostSensitive → AUC: 0.7725\n",
            "Fold 3 | RF+CostSensitive → AUC: 0.7778\n",
            "Fold 4 | RF+CostSensitive → AUC: 0.7728\n",
            "Fold 1 | XGB+None         → AUC: 0.7644\n",
            "Fold 2 | XGB+None         → AUC: 0.7571\n",
            "Fold 3 | XGB+None         → AUC: 0.7634\n",
            "Fold 4 | XGB+None         → AUC: 0.7542\n",
            "Fold 1 | XGB+SMOTE        → AUC: 0.7515\n",
            "Fold 2 | XGB+SMOTE        → AUC: 0.7484\n",
            "Fold 3 | XGB+SMOTE        → AUC: 0.7576\n",
            "Fold 4 | XGB+SMOTE        → AUC: 0.7512\n",
            "Fold 1 | XGB+Borderline   → AUC: 0.7640\n",
            "Fold 2 | XGB+Borderline   → AUC: 0.7406\n",
            "Fold 3 | XGB+Borderline   → AUC: 0.7561\n",
            "Fold 4 | XGB+Borderline   → AUC: 0.7441\n",
            "Fold 1 | XGB+ADASYN       → AUC: 0.7555\n",
            "Fold 2 | XGB+ADASYN       → AUC: 0.7407\n",
            "Fold 3 | XGB+ADASYN       → AUC: 0.7552\n",
            "Fold 4 | XGB+ADASYN       → AUC: 0.7428\n",
            "Fold 1 | XGB+SMOTEENN     → AUC: 0.7716\n",
            "Fold 2 | XGB+SMOTEENN     → AUC: 0.7559\n",
            "Fold 3 | XGB+SMOTEENN     → AUC: 0.7681\n",
            "Fold 4 | XGB+SMOTEENN     → AUC: 0.7616\n",
            "Fold 1 | XGB+SMOTETomek   → AUC: 0.7609\n",
            "Fold 2 | XGB+SMOTETomek   → AUC: 0.7411\n",
            "Fold 3 | XGB+SMOTETomek   → AUC: 0.7565\n",
            "Fold 4 | XGB+SMOTETomek   → AUC: 0.7507\n",
            "Fold 1 | XGB+Under        → AUC: 0.7601\n",
            "Fold 2 | XGB+Under        → AUC: 0.7555\n",
            "Fold 3 | XGB+Under        → AUC: 0.7642\n",
            "Fold 4 | XGB+Under        → AUC: 0.7568\n",
            "Fold 1 | XGB+CostSensitive → AUC: 0.7612\n",
            "Fold 2 | XGB+CostSensitive → AUC: 0.7560\n",
            "Fold 3 | XGB+CostSensitive → AUC: 0.7569\n",
            "Fold 4 | XGB+CostSensitive → AUC: 0.7551\n",
            "Fold 1 | LGB+None         → AUC: 0.7861\n",
            "Fold 2 | LGB+None         → AUC: 0.7733\n",
            "Fold 3 | LGB+None         → AUC: 0.7793\n",
            "Fold 4 | LGB+None         → AUC: 0.7720\n",
            "Fold 1 | LGB+SMOTE        → AUC: 0.7706\n",
            "Fold 2 | LGB+SMOTE        → AUC: 0.7571\n",
            "Fold 3 | LGB+SMOTE        → AUC: 0.7726\n",
            "Fold 4 | LGB+SMOTE        → AUC: 0.7584\n",
            "Fold 1 | LGB+Borderline   → AUC: 0.7733\n",
            "Fold 2 | LGB+Borderline   → AUC: 0.7520\n",
            "Fold 3 | LGB+Borderline   → AUC: 0.7763\n",
            "Fold 4 | LGB+Borderline   → AUC: 0.7596\n",
            "Fold 1 | LGB+ADASYN       → AUC: 0.7674\n",
            "Fold 2 | LGB+ADASYN       → AUC: 0.7544\n",
            "Fold 3 | LGB+ADASYN       → AUC: 0.7695\n",
            "Fold 4 | LGB+ADASYN       → AUC: 0.7554\n",
            "Fold 1 | LGB+SMOTEENN     → AUC: 0.7762\n",
            "Fold 2 | LGB+SMOTEENN     → AUC: 0.7630\n",
            "Fold 3 | LGB+SMOTEENN     → AUC: 0.7810\n",
            "Fold 4 | LGB+SMOTEENN     → AUC: 0.7667\n",
            "Fold 1 | LGB+SMOTETomek   → AUC: 0.7696\n",
            "Fold 2 | LGB+SMOTETomek   → AUC: 0.7597\n",
            "Fold 3 | LGB+SMOTETomek   → AUC: 0.7729\n",
            "Fold 4 | LGB+SMOTETomek   → AUC: 0.7587\n",
            "Fold 1 | LGB+Under        → AUC: 0.7820\n",
            "Fold 2 | LGB+Under        → AUC: 0.7744\n",
            "Fold 3 | LGB+Under        → AUC: 0.7808\n",
            "Fold 4 | LGB+Under        → AUC: 0.7742\n",
            "Fold 1 | LGB+CostSensitive → AUC: 0.7863\n",
            "Fold 2 | LGB+CostSensitive → AUC: 0.7720\n",
            "Fold 3 | LGB+CostSensitive → AUC: 0.7815\n",
            "Fold 4 | LGB+CostSensitive → AUC: 0.7737\n",
            "\n",
            "=== TAIWAN DATASET – FINAL METRICS (4-fold CV) ===\n",
            "Model       Sampler  Method    AUC     CV  Stability  Jaccard      I  T(α=0.5)\n",
            "   RF          None    SHAP 0.7801 0.6131     0.3869   0.8333 0.6101    0.9908\n",
            "   RF          None Banzhaf 0.7801 0.8515     0.1485   0.3261 0.2373    0.6387\n",
            "   RF          None    Owen 0.7801 0.9274     0.0726   0.2401 0.1564    0.5622\n",
            "   RF         SMOTE    SHAP 0.7746 0.6049     0.3951   0.7222 0.5587    0.8552\n",
            "   RF         SMOTE Banzhaf 0.7746 0.7325     0.2675   0.4087 0.3381    0.6468\n",
            "   RF         SMOTE    Owen 0.7746 1.0358    -0.0358   0.3558 0.1600    0.4786\n",
            "   RF    Borderline    SHAP 0.7722 0.6140     0.3860   0.7778 0.5819    0.8384\n",
            "   RF    Borderline Banzhaf 0.7722 0.7121     0.2879   0.4782 0.3830    0.6506\n",
            "   RF    Borderline    Owen 0.7722 0.9126     0.0874   0.3095 0.1985    0.4763\n",
            "   RF        ADASYN    SHAP 0.7718 0.6337     0.3663   0.7222 0.5443    0.7969\n",
            "   RF        ADASYN Banzhaf 0.7718 0.7162     0.2838   0.3161 0.2999    0.5662\n",
            "   RF        ADASYN    Owen 0.7718 0.9901     0.0099   0.3029 0.1564    0.4306\n",
            "   RF      SMOTEENN    SHAP 0.7750 0.5966     0.4034   0.7222 0.5628    0.8647\n",
            "   RF      SMOTEENN Banzhaf 0.7750 0.7350     0.2650   0.3161 0.2906    0.6076\n",
            "   RF      SMOTEENN    Owen 0.7750 1.0136    -0.0136   0.4345 0.2105    0.5319\n",
            "   RF    SMOTETomek    SHAP 0.7754 0.6142     0.3858   0.7222 0.5540    0.8623\n",
            "   RF    SMOTETomek Banzhaf 0.7754 0.7173     0.2827   0.4253 0.3540    0.6734\n",
            "   RF    SMOTETomek    Owen 0.7754 0.9536     0.0464   0.3492 0.1978    0.5259\n",
            "   RF         Under    SHAP 0.7795 0.6031     0.3969   0.7222 0.5596    0.9338\n",
            "   RF         Under Banzhaf 0.7795 0.8075     0.1925   0.3095 0.2510    0.6423\n",
            "   RF         Under    Owen 0.7795 0.9449     0.0551   0.2798 0.1674    0.5634\n",
            "   RF CostSensitive    SHAP 0.7777 0.5937     0.4063   0.8333 0.6198    0.9609\n",
            "   RF CostSensitive Banzhaf 0.7777 0.7995     0.2005   0.3459 0.2732    0.6335\n",
            "   RF CostSensitive    Owen 0.7777 0.9430     0.0570   0.1620 0.1095    0.4790\n",
            "  XGB          None    SHAP 0.7598 0.6703     0.3297   0.8333 0.5815    0.6420\n",
            "  XGB          None Banzhaf 0.7598 0.8317     0.1683   0.2930 0.2306    0.3106\n",
            "  XGB          None    Owen 0.7598 0.9831     0.0169   0.1640 0.0905    0.1782\n",
            "  XGB         SMOTE    SHAP 0.7522 0.6477     0.3523   0.6429 0.4976    0.4422\n",
            "  XGB         SMOTE Banzhaf 0.7522 0.7832     0.2168   0.8333 0.5251    0.4682\n",
            "  XGB         SMOTE    Owen 0.7522 1.0617    -0.0617   0.2566 0.0974    0.0642\n",
            "  XGB    Borderline    SHAP 0.7512 0.6301     0.3699   0.5873 0.4786    0.4085\n",
            "  XGB    Borderline Banzhaf 0.7512 0.7696     0.2304   0.5873 0.4089    0.3427\n",
            "  XGB    Borderline    Owen 0.7512 1.0498    -0.0498   0.3327 0.1414    0.0901\n",
            "  XGB        ADASYN    SHAP 0.7485 0.6296     0.3704   0.6270 0.4987    0.3856\n",
            "  XGB        ADASYN Banzhaf 0.7485 0.7757     0.2243   0.5476 0.3860    0.2791\n",
            "  XGB        ADASYN    Owen 0.7485 0.9721     0.0279   0.2632 0.1455    0.0520\n",
            "  XGB      SMOTEENN    SHAP 0.7643 0.6558     0.3442   0.5873 0.4658    0.6040\n",
            "  XGB      SMOTEENN Banzhaf 0.7643 0.8044     0.1956   0.4187 0.3072    0.4542\n",
            "  XGB      SMOTEENN    Owen 0.7643 1.0503    -0.0503   0.3095 0.1296    0.2865\n",
            "  XGB    SMOTETomek    SHAP 0.7523 0.6114     0.3886   0.5873 0.4880    0.4348\n",
            "  XGB    SMOTETomek Banzhaf 0.7523 0.7924     0.2076   0.6825 0.4451    0.3943\n",
            "  XGB    SMOTETomek    Owen 0.7523 1.0252    -0.0252   0.2566 0.1157    0.0832\n",
            "  XGB         Under    SHAP 0.7591 0.6546     0.3454   0.6270 0.4862    0.5414\n",
            "  XGB         Under Banzhaf 0.7591 0.8192     0.1808   0.2401 0.2104    0.2810\n",
            "  XGB         Under    Owen 0.7591 0.9094     0.0906   0.2103 0.1504    0.2243\n",
            "  XGB CostSensitive    SHAP 0.7573 0.6700     0.3300   0.7778 0.5539    0.5762\n",
            "  XGB CostSensitive Banzhaf 0.7573 0.8396     0.1604   0.1687 0.1645    0.2085\n",
            "  XGB CostSensitive    Owen 0.7573 0.9372     0.0628   0.2269 0.1448    0.1899\n",
            "  LGB          None    SHAP 0.7777 0.6754     0.3246   0.6825 0.5036    0.8515\n",
            "  LGB          None Banzhaf 0.7777 0.8848     0.1152   0.2864 0.2008    0.5655\n",
            "  LGB          None    Owen 0.7777 0.9376     0.0624   0.1270 0.0947    0.4653\n",
            "  LGB         SMOTE    SHAP 0.7647 0.6834     0.3166   0.6825 0.4996    0.6416\n",
            "  LGB         SMOTE Banzhaf 0.7647 0.7716     0.2284   0.5238 0.3761    0.5250\n",
            "  LGB         SMOTE    Owen 0.7647 0.9139     0.0861   0.3161 0.2011    0.3597\n",
            "  LGB    Borderline    SHAP 0.7653 0.6680     0.3320   0.5476 0.4398    0.5957\n",
            "  LGB    Borderline Banzhaf 0.7653 0.7809     0.2191   0.5476 0.3834    0.5424\n",
            "  LGB    Borderline    Owen 0.7653 0.9691     0.0309   0.4286 0.2297    0.3972\n",
            "  LGB        ADASYN    SHAP 0.7617 0.6573     0.3427   0.7222 0.5324    0.6253\n",
            "  LGB        ADASYN Banzhaf 0.7617 0.7764     0.2236   0.5179 0.3707    0.4725\n",
            "  LGB        ADASYN    Owen 0.7617 0.9638     0.0362   0.4385 0.2373    0.3465\n",
            "  LGB      SMOTEENN    SHAP 0.7717 0.6226     0.3774   0.4940 0.4357    0.6932\n",
            "  LGB      SMOTEENN Banzhaf 0.7717 0.8440     0.1560   0.5079 0.3320    0.5952\n",
            "  LGB      SMOTEENN    Owen 0.7717 1.0074    -0.0074   0.2864 0.1395    0.4134\n",
            "  LGB    SMOTETomek    SHAP 0.7652 0.6438     0.3562   0.5873 0.4717    0.6241\n",
            "  LGB    SMOTETomek Banzhaf 0.7652 0.7725     0.2275   0.5079 0.3677    0.5258\n",
            "  LGB    SMOTETomek    Owen 0.7652 0.9614     0.0386   0.5476 0.2931    0.4554\n",
            "  LGB         Under    SHAP 0.7779 0.6410     0.3590   0.5873 0.4731    0.8259\n",
            "  LGB         Under Banzhaf 0.7779 0.8779     0.1221   0.3690 0.2456    0.6110\n",
            "  LGB         Under    Owen 0.7779 1.0007    -0.0007   0.2103 0.1048    0.4780\n",
            "  LGB CostSensitive    SHAP 0.7784 0.6923     0.3077   0.8333 0.5705    0.9255\n",
            "  LGB CostSensitive Banzhaf 0.7784 0.8708     0.1292   0.3029 0.2160    0.5907\n",
            "  LGB CostSensitive    Owen 0.7784 0.8952     0.1048   0.1157 0.1103    0.4908\n",
            "\n",
            "=== Average by Explanation Method ===\n",
            "            AUC  Stability  Jaccard       I  T(α=0.5)\n",
            "Method                                               \n",
            "Banzhaf  0.7672     0.2056   0.4275  0.3165    0.5094\n",
            "Owen     0.7672     0.0267   0.2885  0.1576    0.3593\n",
            "SHAP     0.7672     0.3614   0.6859  0.5237    0.7050\n",
            "\n",
            "LaTeX TABLE — SHAP:\n",
            "\\begin{table}\n",
            "\\caption{Taiwan Dataset – SHAP Results (4-fold CV)}\n",
            "\\label{tab:taiwan_shap}\n",
            "\\begin{tabular}{llrrrrr}\n",
            "\\toprule\n",
            "Model & Sampler & AUC & Stability & Jaccard & I & T(α=0.5) \\\\\n",
            "\\midrule\n",
            "RF & None & 0.780100 & 0.386900 & 0.833300 & 0.610100 & 0.990800 \\\\\n",
            "RF & SMOTE & 0.774600 & 0.395100 & 0.722200 & 0.558700 & 0.855200 \\\\\n",
            "RF & Borderline & 0.772200 & 0.386000 & 0.777800 & 0.581900 & 0.838400 \\\\\n",
            "RF & ADASYN & 0.771800 & 0.366300 & 0.722200 & 0.544300 & 0.796900 \\\\\n",
            "RF & SMOTEENN & 0.775000 & 0.403400 & 0.722200 & 0.562800 & 0.864700 \\\\\n",
            "RF & SMOTETomek & 0.775400 & 0.385800 & 0.722200 & 0.554000 & 0.862300 \\\\\n",
            "RF & Under & 0.779500 & 0.396900 & 0.722200 & 0.559600 & 0.933800 \\\\\n",
            "RF & CostSensitive & 0.777700 & 0.406300 & 0.833300 & 0.619800 & 0.960900 \\\\\n",
            "XGB & None & 0.759800 & 0.329700 & 0.833300 & 0.581500 & 0.642000 \\\\\n",
            "XGB & SMOTE & 0.752200 & 0.352300 & 0.642900 & 0.497600 & 0.442200 \\\\\n",
            "XGB & Borderline & 0.751200 & 0.369900 & 0.587300 & 0.478600 & 0.408500 \\\\\n",
            "XGB & ADASYN & 0.748500 & 0.370400 & 0.627000 & 0.498700 & 0.385600 \\\\\n",
            "XGB & SMOTEENN & 0.764300 & 0.344200 & 0.587300 & 0.465800 & 0.604000 \\\\\n",
            "XGB & SMOTETomek & 0.752300 & 0.388600 & 0.587300 & 0.488000 & 0.434800 \\\\\n",
            "XGB & Under & 0.759100 & 0.345400 & 0.627000 & 0.486200 & 0.541400 \\\\\n",
            "XGB & CostSensitive & 0.757300 & 0.330000 & 0.777800 & 0.553900 & 0.576200 \\\\\n",
            "LGB & None & 0.777700 & 0.324600 & 0.682500 & 0.503600 & 0.851500 \\\\\n",
            "LGB & SMOTE & 0.764700 & 0.316600 & 0.682500 & 0.499600 & 0.641600 \\\\\n",
            "LGB & Borderline & 0.765300 & 0.332000 & 0.547600 & 0.439800 & 0.595700 \\\\\n",
            "LGB & ADASYN & 0.761700 & 0.342700 & 0.722200 & 0.532400 & 0.625300 \\\\\n",
            "LGB & SMOTEENN & 0.771700 & 0.377400 & 0.494000 & 0.435700 & 0.693200 \\\\\n",
            "LGB & SMOTETomek & 0.765200 & 0.356200 & 0.587300 & 0.471700 & 0.624100 \\\\\n",
            "LGB & Under & 0.777900 & 0.359000 & 0.587300 & 0.473100 & 0.825900 \\\\\n",
            "LGB & CostSensitive & 0.778400 & 0.307700 & 0.833300 & 0.570500 & 0.925500 \\\\\n",
            "\\bottomrule\n",
            "\\end{tabular}\n",
            "\\end{table}\n",
            "\n",
            "\n",
            "LaTeX TABLE — Banzhaf:\n",
            "\\begin{table}\n",
            "\\caption{Taiwan Dataset – Banzhaf Results (4-fold CV)}\n",
            "\\label{tab:taiwan_banzhaf}\n",
            "\\begin{tabular}{llrrrrr}\n",
            "\\toprule\n",
            "Model & Sampler & AUC & Stability & Jaccard & I & T(α=0.5) \\\\\n",
            "\\midrule\n",
            "RF & None & 0.780100 & 0.148500 & 0.326100 & 0.237300 & 0.638700 \\\\\n",
            "RF & SMOTE & 0.774600 & 0.267500 & 0.408700 & 0.338100 & 0.646800 \\\\\n",
            "RF & Borderline & 0.772200 & 0.287900 & 0.478200 & 0.383000 & 0.650600 \\\\\n",
            "RF & ADASYN & 0.771800 & 0.283800 & 0.316100 & 0.299900 & 0.566200 \\\\\n",
            "RF & SMOTEENN & 0.775000 & 0.265000 & 0.316100 & 0.290600 & 0.607600 \\\\\n",
            "RF & SMOTETomek & 0.775400 & 0.282700 & 0.425300 & 0.354000 & 0.673400 \\\\\n",
            "RF & Under & 0.779500 & 0.192500 & 0.309500 & 0.251000 & 0.642300 \\\\\n",
            "RF & CostSensitive & 0.777700 & 0.200500 & 0.345900 & 0.273200 & 0.633500 \\\\\n",
            "XGB & None & 0.759800 & 0.168300 & 0.293000 & 0.230600 & 0.310600 \\\\\n",
            "XGB & SMOTE & 0.752200 & 0.216800 & 0.833300 & 0.525100 & 0.468200 \\\\\n",
            "XGB & Borderline & 0.751200 & 0.230400 & 0.587300 & 0.408900 & 0.342700 \\\\\n",
            "XGB & ADASYN & 0.748500 & 0.224300 & 0.547600 & 0.386000 & 0.279100 \\\\\n",
            "XGB & SMOTEENN & 0.764300 & 0.195600 & 0.418700 & 0.307200 & 0.454200 \\\\\n",
            "XGB & SMOTETomek & 0.752300 & 0.207600 & 0.682500 & 0.445100 & 0.394300 \\\\\n",
            "XGB & Under & 0.759100 & 0.180800 & 0.240100 & 0.210400 & 0.281000 \\\\\n",
            "XGB & CostSensitive & 0.757300 & 0.160400 & 0.168700 & 0.164500 & 0.208500 \\\\\n",
            "LGB & None & 0.777700 & 0.115200 & 0.286400 & 0.200800 & 0.565500 \\\\\n",
            "LGB & SMOTE & 0.764700 & 0.228400 & 0.523800 & 0.376100 & 0.525000 \\\\\n",
            "LGB & Borderline & 0.765300 & 0.219100 & 0.547600 & 0.383400 & 0.542400 \\\\\n",
            "LGB & ADASYN & 0.761700 & 0.223600 & 0.517900 & 0.370700 & 0.472500 \\\\\n",
            "LGB & SMOTEENN & 0.771700 & 0.156000 & 0.507900 & 0.332000 & 0.595200 \\\\\n",
            "LGB & SMOTETomek & 0.765200 & 0.227500 & 0.507900 & 0.367700 & 0.525800 \\\\\n",
            "LGB & Under & 0.777900 & 0.122100 & 0.369000 & 0.245600 & 0.611000 \\\\\n",
            "LGB & CostSensitive & 0.778400 & 0.129200 & 0.302900 & 0.216000 & 0.590700 \\\\\n",
            "\\bottomrule\n",
            "\\end{tabular}\n",
            "\\end{table}\n",
            "\n",
            "\n",
            "LaTeX TABLE — Owen:\n",
            "\\begin{table}\n",
            "\\caption{Taiwan Dataset – Owen Results (4-fold CV)}\n",
            "\\label{tab:taiwan_owen}\n",
            "\\begin{tabular}{llrrrrr}\n",
            "\\toprule\n",
            "Model & Sampler & AUC & Stability & Jaccard & I & T(α=0.5) \\\\\n",
            "\\midrule\n",
            "RF & None & 0.780100 & 0.072600 & 0.240100 & 0.156400 & 0.562200 \\\\\n",
            "RF & SMOTE & 0.774600 & -0.035800 & 0.355800 & 0.160000 & 0.478600 \\\\\n",
            "RF & Borderline & 0.772200 & 0.087400 & 0.309500 & 0.198500 & 0.476300 \\\\\n",
            "RF & ADASYN & 0.771800 & 0.009900 & 0.302900 & 0.156400 & 0.430600 \\\\\n",
            "RF & SMOTEENN & 0.775000 & -0.013600 & 0.434500 & 0.210500 & 0.531900 \\\\\n",
            "RF & SMOTETomek & 0.775400 & 0.046400 & 0.349200 & 0.197800 & 0.525900 \\\\\n",
            "RF & Under & 0.779500 & 0.055100 & 0.279800 & 0.167400 & 0.563400 \\\\\n",
            "RF & CostSensitive & 0.777700 & 0.057000 & 0.162000 & 0.109500 & 0.479000 \\\\\n",
            "XGB & None & 0.759800 & 0.016900 & 0.164000 & 0.090500 & 0.178200 \\\\\n",
            "XGB & SMOTE & 0.752200 & -0.061700 & 0.256600 & 0.097400 & 0.064200 \\\\\n",
            "XGB & Borderline & 0.751200 & -0.049800 & 0.332700 & 0.141400 & 0.090100 \\\\\n",
            "XGB & ADASYN & 0.748500 & 0.027900 & 0.263200 & 0.145500 & 0.052000 \\\\\n",
            "XGB & SMOTEENN & 0.764300 & -0.050300 & 0.309500 & 0.129600 & 0.286500 \\\\\n",
            "XGB & SMOTETomek & 0.752300 & -0.025200 & 0.256600 & 0.115700 & 0.083200 \\\\\n",
            "XGB & Under & 0.759100 & 0.090600 & 0.210300 & 0.150400 & 0.224300 \\\\\n",
            "XGB & CostSensitive & 0.757300 & 0.062800 & 0.226900 & 0.144800 & 0.189900 \\\\\n",
            "LGB & None & 0.777700 & 0.062400 & 0.127000 & 0.094700 & 0.465300 \\\\\n",
            "LGB & SMOTE & 0.764700 & 0.086100 & 0.316100 & 0.201100 & 0.359700 \\\\\n",
            "LGB & Borderline & 0.765300 & 0.030900 & 0.428600 & 0.229700 & 0.397200 \\\\\n",
            "LGB & ADASYN & 0.761700 & 0.036200 & 0.438500 & 0.237300 & 0.346500 \\\\\n",
            "LGB & SMOTEENN & 0.771700 & -0.007400 & 0.286400 & 0.139500 & 0.413400 \\\\\n",
            "LGB & SMOTETomek & 0.765200 & 0.038600 & 0.547600 & 0.293100 & 0.455400 \\\\\n",
            "LGB & Under & 0.777900 & -0.000700 & 0.210300 & 0.104800 & 0.478000 \\\\\n",
            "LGB & CostSensitive & 0.778400 & 0.104800 & 0.115700 & 0.110300 & 0.490800 \\\\\n",
            "\\bottomrule\n",
            "\\end{tabular}\n",
            "\\end{table}\n",
            "\n",
            "\n",
            "SUMMARY LaTeX:\n",
            " \\begin{table}\n",
            "\\caption{Taiwan Dataset – Method Comparison}\n",
            "\\label{tab:taiwan_summary}\n",
            "\\begin{tabular}{lrrrrr}\n",
            "\\toprule\n",
            " & AUC & Stability & Jaccard & I & T(α=0.5) \\\\\n",
            "Method &  &  &  &  &  \\\\\n",
            "\\midrule\n",
            "Banzhaf & 0.767200 & 0.205600 & 0.427500 & 0.316500 & 0.509400 \\\\\n",
            "Owen & 0.767200 & 0.026700 & 0.288500 & 0.157600 & 0.359300 \\\\\n",
            "SHAP & 0.767200 & 0.361400 & 0.685900 & 0.523700 & 0.705000 \\\\\n",
            "\\bottomrule\n",
            "\\end{tabular}\n",
            "\\end{table}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Taiwan Credit Card Default – Rigorous Accuracy–Interpretability Study (Code B style)\"\"\"\n",
        "\n",
        "# ============================================================\n",
        "# 1. Install & Imports\n",
        "# ============================================================\n",
        "!pip install -q imbalanced-learn shap lightgbm xgboost seaborn scikit-learn pandas numpy matplotlib\n",
        "\n",
        "import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns, warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb, lightgbm as lgb\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN\n",
        "from imblearn.combine import SMOTEENN, SMOTETomek\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "import shap\n",
        "\n",
        "plt.style.use('default'); sns.set_palette(\"husl\"); np.random.seed(42)\n",
        "\n",
        "# ============================================================\n",
        "# 2. Load & Preprocess Taiwan Dataset\n",
        "# ============================================================\n",
        "import kagglehub, os\n",
        "path = kagglehub.dataset_download(\"uciml/default-of-credit-card-clients-dataset\")\n",
        "csv_path = os.path.join(path, \"UCI_Credit_Card.csv\")\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Clean\n",
        "df = df.drop(columns=['ID']) if 'ID' in df.columns else df\n",
        "df.rename(columns={'default.payment.next.month': 'target'}, inplace=True)\n",
        "df['target'] = df['target'].astype(int)\n",
        "\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Categorical & numeric\n",
        "cat_cols = ['SEX', 'EDUCATION', 'MARRIAGE']\n",
        "num_cols = [c for c in X.columns if c not in cat_cols]\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), cat_cols),\n",
        "    ('num', StandardScaler(), num_cols)\n",
        "])\n",
        "\n",
        "# ============================================================\n",
        "# 3. Models & Samplers\n",
        "# ============================================================\n",
        "models = {\n",
        "    'RF': RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1),\n",
        "    'XGB': xgb.XGBClassifier(n_estimators=100, max_depth=6, random_state=42, eval_metric='logloss', n_jobs=-1),\n",
        "    'LGB': lgb.LGBMClassifier(n_estimators=100, max_depth=6, random_state=42, verbose=-1, n_jobs=-1)\n",
        "}\n",
        "\n",
        "resamplers = {\n",
        "    'None': None,\n",
        "    'SMOTE': SMOTE(random_state=42),\n",
        "    'Borderline': BorderlineSMOTE(random_state=42),\n",
        "    'ADASYN': ADASYN(random_state=42),\n",
        "    'SMOTEENN': SMOTEENN(random_state=42),\n",
        "    'SMOTETomek': SMOTETomek(random_state=42),\n",
        "    'Under': RandomUnderSampler(random_state=42),\n",
        "    'CostSensitive': 'cost'\n",
        "}\n",
        "\n",
        "classes = np.unique(y)\n",
        "weights = compute_class_weight(class_weight='balanced', classes=classes, y=y)\n",
        "class_weight_dict = {int(cls): float(w) for cls, w in zip(classes, weights)}\n",
        "\n",
        "# ============================================================\n",
        "# 4. Explanation Functions (same as Code B)\n",
        "# ============================================================\n",
        "def get_shap_reliable(pipe, X_test):\n",
        "    clf = pipe.named_steps['clf']\n",
        "    X_proc = pipe.named_steps['prep'].transform(X_test)\n",
        "    try:\n",
        "        explainer = shap.TreeExplainer(clf)\n",
        "        sv = explainer.shap_values(X_proc)\n",
        "        return sv[1] if isinstance(sv, list) else sv\n",
        "    except:\n",
        "        from sklearn.inspection import permutation_importance\n",
        "        res = permutation_importance(clf, X_proc, pipe.predict(X_proc), n_repeats=3, random_state=42)\n",
        "        return np.tile(res.importances_mean, (X_proc.shape[0], 1))\n",
        "\n",
        "def compute_banzhaf(pipe, X_test, n_samples=5, max_instances=5):\n",
        "    clf = pipe.named_steps['clf']\n",
        "    X_proc = pipe.named_steps['prep'].transform(X_test)\n",
        "    n_feat = X_proc.shape[1]\n",
        "    n_inst = min(max_instances, X_proc.shape[0])\n",
        "    mat = np.zeros((n_inst, n_feat))\n",
        "    for i in range(n_inst):\n",
        "        x = X_proc[i:i+1]\n",
        "        for f in range(n_feat):\n",
        "            contrib = []\n",
        "            for _ in range(n_samples):\n",
        "                coal = np.random.binomial(1, 0.5, n_feat)\n",
        "                coal[f] = 0\n",
        "                p0 = clf.predict_proba(x * coal.reshape(1, -1))[0, 1]\n",
        "                coal[f] = 1\n",
        "                p1 = clf.predict_proba(x * coal.reshape(1, -1))[0, 1]\n",
        "                contrib.append(p1 - p0)\n",
        "            mat[i, f] = np.mean(contrib)\n",
        "    return mat\n",
        "\n",
        "feature_groups = {\n",
        "    'Demographic': ['SEX', 'EDUCATION', 'MARRIAGE', 'AGE'],\n",
        "    'Limit': ['LIMIT_BAL'],\n",
        "    'History': [c for c in X.columns if 'PAY_' in c],\n",
        "    'Bill': [c for c in X.columns if 'BILL_AMT' in c],\n",
        "    'Payment': [c for c in X.columns if 'PAY_AMT' in c]\n",
        "}\n",
        "\n",
        "def compute_owen(pipe, X_test, feature_groups, n_samples=3, max_instances=5):\n",
        "    clf = pipe.named_steps['clf']; prep = pipe.named_steps['prep']\n",
        "    X_proc = prep.transform(X_test)\n",
        "    fnames = prep.get_feature_names_out()\n",
        "    group_idx = {g: [i for i, n in enumerate(fnames) if any(f in n for f in feats)]\n",
        "                 for g, feats in feature_groups.items()}\n",
        "    n_feat = X_proc.shape[1]\n",
        "    n_inst = min(max_instances, X_proc.shape[0])\n",
        "    mat = np.zeros((n_inst, n_feat))\n",
        "    for i in range(n_inst):\n",
        "        x = X_proc[i:i+1]\n",
        "        for f in range(n_feat):\n",
        "            contrib = []\n",
        "            for _ in range(n_samples):\n",
        "                gmask = {g: np.random.choice([0,1]) for g in group_idx}\n",
        "                mask = np.zeros(n_feat)\n",
        "                for g, idxs in group_idx.items():\n",
        "                    if gmask[g]:\n",
        "                        if f in idxs:\n",
        "                            for idx in idxs: mask[idx] = np.random.choice([0,1])\n",
        "                        else: mask[idxs] = 1\n",
        "                mask0 = mask.copy(); mask0[f] = 0\n",
        "                p0 = clf.predict_proba(x * mask0)[0,1]\n",
        "                p1 = clf.predict_proba(x * mask)[0,1]\n",
        "                contrib.append(p1 - p0)\n",
        "            mat[i, f] = np.mean(contrib)\n",
        "    return mat\n",
        "\n",
        "# ============================================================\n",
        "# 5. Metrics (identical to Code B)\n",
        "# ============================================================\n",
        "#\n",
        "def stability_cv(expl_list):\n",
        "    if len(expl_list) < 2:\n",
        "        return 1.0\n",
        "    arr = np.stack([np.abs(e) for e in expl_list])           # shape: (n_folds, n_samples, n_features)\n",
        "    mean = arr.mean(axis=0) + 1e-8\n",
        "    std = arr.std(axis=0)\n",
        "    cv_per_feature = std / mean\n",
        "    return float(np.mean(cv_per_feature))                    # scalar\n",
        "\n",
        "def jaccard_topk(expl_list, k=5):\n",
        "    if len(expl_list) < 2:\n",
        "        return 0.0\n",
        "    sets = []\n",
        "    for exp in expl_list:\n",
        "        # Mean absolute SHAP/value per feature across instances\n",
        "        imp = np.abs(exp).mean(axis=0).ravel()\n",
        "        # Get indices of top-k features → convert to tuple (hashable!)\n",
        "        topk_indices = tuple(np.argsort(imp)[-k:].tolist())\n",
        "        sets.append(topk_indices)\n",
        "\n",
        "    # Pairwise Jaccard\n",
        "    sims = []\n",
        "    for i in range(len(sets)):\n",
        "        for j in range(i + 1, len(sets)):\n",
        "            inter = len(set(sets[i]) & set(sets[j]))\n",
        "            union = len(set(sets[i]) | set(sets[j]))\n",
        "            sims.append(inter / union if union > 0 else 0.0)\n",
        "    return float(np.mean(sims)) if sims else 0.0\n",
        "\n",
        "def interpretability_score(cv, j, beta=0.5):\n",
        "    return beta * (1 - cv) + (1 - beta) * j\n",
        "\n",
        "def normalize(s):\n",
        "    return (s - s.min()) / (s.max() - s.min() + 1e-8)\n",
        "\n",
        "def tradeoff_metric(auc_series, I_series, alpha=0.5):\n",
        "    return alpha * normalize(auc_series) + (1-alpha) * normalize(I_series)\n",
        "\n",
        "# ============================================================\n",
        "# 6. 4-Fold CV Loop (the gold standard)\n",
        "# ============================================================\n",
        "cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
        "records = []\n",
        "\n",
        "for mname, model in models.items():\n",
        "    for sname, sampler in resamplers.items():\n",
        "        aucs = []\n",
        "        shap_runs, banzhaf_runs, owen_runs = [], [], []\n",
        "\n",
        "        for fold, (train_idx, test_idx) in enumerate(cv.split(X, y), 1):\n",
        "            X_tr, X_te = X.iloc[train_idx], X.iloc[test_idx]\n",
        "            y_tr, y_te = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "            steps = [('prep', preprocessor)]\n",
        "            if sampler and sampler != 'cost':\n",
        "                steps.append(('samp', sampler))\n",
        "            steps.append(('clf', model))\n",
        "            pipe = ImbPipeline(steps)\n",
        "\n",
        "            # Cost-sensitive\n",
        "            if sname == 'CostSensitive':\n",
        "                if mname == 'RF':\n",
        "                    pipe.named_steps['clf'].set_params(class_weight=class_weight_dict)\n",
        "                elif mname == 'XGB':\n",
        "                    ratio = class_weight_dict[1] / class_weight_dict[0]\n",
        "                    pipe.named_steps['clf'].set_params(scale_pos_weight=ratio)\n",
        "                elif mname == 'LGB':\n",
        "                    pipe.named_steps['clf'].set_params(class_weight=class_weight_dict)\n",
        "\n",
        "            pipe.fit(X_tr, y_tr)\n",
        "            auc = roc_auc_score(y_te, pipe.predict_proba(X_te)[:, 1])\n",
        "            aucs.append(auc)\n",
        "            print(f\"Fold {fold} | {mname}+{sname:12} → AUC: {auc:.4f}\")\n",
        "\n",
        "            # Explanations on small sample\n",
        "            X_sample = X_te.sample(n=min(50, len(X_te)), random_state=42)\n",
        "            shap_runs.append(get_shap_reliable(pipe, X_sample))\n",
        "            banzhaf_runs.append(compute_banzhaf(pipe, X_sample))\n",
        "            owen_runs.append(compute_owen(pipe, X_sample, feature_groups))\n",
        "\n",
        "        # Aggregate\n",
        "        auc_mean = np.mean(aucs)\n",
        "        for method, runs in zip(['SHAP','Banzhaf','Owen'], [shap_runs, banzhaf_runs, owen_runs]):\n",
        "            cv_val = stability_cv(runs)\n",
        "            jacc = jaccard_topk(runs)\n",
        "            I = interpretability_score(cv_val, jacc)\n",
        "            records.append({\n",
        "                'Model': mname, 'Sampler': sname, 'Method': method,\n",
        "                'AUC': auc_mean, 'CV': cv_val, 'Stability': 1-cv_val,\n",
        "                'Jaccard': jacc, 'I': I\n",
        "            })\n",
        "\n",
        "# ============================================================\n",
        "# 7. Results & Visualisations\n",
        "# ============================================================\n",
        "metrics = pd.DataFrame(records)\n",
        "metrics['T(α=0.5)'] = tradeoff_metric(metrics['AUC'], metrics['I'])\n",
        "\n",
        "print(\"\\n=== TAIWAN DATASET – FINAL METRICS (4-fold CV) ===\")\n",
        "print(metrics.round(4).to_string(index=False))\n",
        "\n",
        "# Average by method\n",
        "print(\"\\n=== Average by Explanation Method ===\")\n",
        "print(metrics.groupby('Method')[['AUC','Stability','Jaccard','I','T(α=0.5)']].mean().round(4))\n",
        "\n",
        "# LaTeX tables (copy-paste into thesis)\n",
        "for method in ['SHAP','Banzhaf','Owen']:\n",
        "    subset = metrics[metrics['Method']==method]\n",
        "    latex = subset[['Model','Sampler','AUC','Stability','Jaccard','I','T(α=0.5)']].round(4).to_latex(\n",
        "        index=False, caption=f\"Taiwan Dataset – {method} Results (4-fold CV)\", label=f\"tab:taiwan_{method.lower()}\")\n",
        "    print(f\"\\nLaTeX TABLE — {method}:\\n{latex}\")\n",
        "\n",
        "# Summary table\n",
        "summary = metrics.groupby('Method')[['AUC','Stability','Jaccard','I','T(α=0.5)']].mean().round(4)\n",
        "print(\"\\nSUMMARY LaTeX:\\n\", summary.to_latex(caption=\"Taiwan Dataset – Method Comparison\", label=\"tab:taiwan_summary\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 10. Statistical Validation Suite — Taiwan Dataset\n",
        "# ============================================================\n",
        "\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statsmodels.stats.power import TTestIndPower\n",
        "\n",
        "print(\"\\n================ STATISTICAL VALIDATION SUITE (TAIWAN) ================\\n\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 10.1 Friedman Test (Overall Model Differences)\n",
        "# ------------------------------------------------------------\n",
        "print(\"\\nFriedman's Test for Model Comparisons:\")\n",
        "for metric in ['AUC', 'I', 'T(α=0.5)']:\n",
        "    pivoted = metrics.pivot_table(values=metric, index=['Sampler','Method'], columns='Model')\n",
        "\n",
        "    if len(pivoted) < 3 or pivoted.shape[1] != 3 or pivoted.isnull().any().any():\n",
        "        print(f\"  Skipping {metric}: insufficient data\")\n",
        "        continue\n",
        "\n",
        "    rf, xgb, lgb = pivoted['RF'].values, pivoted['XGB'].values, pivoted['LGB'].values\n",
        "    stat, p = stats.friedmanchisquare(rf, xgb, lgb)\n",
        "\n",
        "    k = pivoted.shape[1]\n",
        "    n = pivoted.shape[0]\n",
        "    kendall_w = stat / (n * (k - 1))\n",
        "\n",
        "    print(f\"  {metric}: stat={stat:.2f}, p={p:.4f} ({'significant' if p<0.05 else 'not significant'})\")\n",
        "    print(f\"    Kendall's W: {kendall_w:.4f}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 10.2 Nemenyi Post-Hoc Test\n",
        "# ------------------------------------------------------------\n",
        "def nemenyi_posthoc(data, model_names, alpha=0.05):\n",
        "    ranks = stats.rankdata(data, axis=1)\n",
        "    mean_ranks = np.mean(ranks, axis=0)\n",
        "    n, k = data.shape\n",
        "    q_alpha = 2.343  # for k=3 at alpha=0.05\n",
        "    cd = q_alpha * np.sqrt(k*(k+1)/(6*n))\n",
        "\n",
        "    print(\"Mean Ranks:\", dict(zip(model_names, mean_ranks)))\n",
        "    print(f\"Critical Difference (CD): {cd:.4f}\")\n",
        "\n",
        "    for i in range(k):\n",
        "        for j in range(i+1, k):\n",
        "            diff = abs(mean_ranks[i] - mean_ranks[j])\n",
        "            sig = \"SIGNIFICANT\" if diff > cd else \"not significant\"\n",
        "            print(f\"  {model_names[i]} vs {model_names[j]}: |rank diff|={diff:.4f} → {sig}\")\n",
        "\n",
        "print(\"\\n================ Nemenyi Post-Hoc Tests ================\")\n",
        "for metric in ['AUC', 'I', 'T(α=0.5)']:\n",
        "    print(f\"\\n=== Nemenyi Test for {metric} ===\")\n",
        "    pivoted = metrics.pivot_table(values=metric, index=['Sampler','Method'], columns='Model')\n",
        "    nemenyi_posthoc(pivoted.values, ['RF','XGB','LGB'])\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 10.3 Wilcoxon Signed-Rank Test\n",
        "# ------------------------------------------------------------\n",
        "print(\"\\n================ Wilcoxon Signed-Rank Tests ================\")\n",
        "pairs = [('RF','XGB'), ('RF','LGB'), ('XGB','LGB')]\n",
        "for metric in ['AUC','I','T(α=0.5)']:\n",
        "    print(f\"\\nWilcoxon Test for {metric}:\")\n",
        "    for m1, m2 in pairs:\n",
        "        df1 = metrics[metrics['Model']==m1][metric].values\n",
        "        df2 = metrics[metrics['Model']==m2][metric].values\n",
        "        stat, p = stats.wilcoxon(df1, df2)\n",
        "        print(f\"  {m1} vs {m2}: stat={stat:.3f}, p={p:.4f}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 10.4 Cliff's Delta (Effect Size)\n",
        "# ------------------------------------------------------------\n",
        "def cliffs_delta(x, y):\n",
        "    comparisons = [1 if xi>yj else -1 if xi<yj else 0 for xi in x for yj in y]\n",
        "    return sum(comparisons) / len(comparisons)\n",
        "\n",
        "def interpret_delta(ad):\n",
        "    ad = abs(ad)\n",
        "    if ad > 0.474: return \"large\"\n",
        "    elif ad > 0.33: return \"medium\"\n",
        "    elif ad > 0.147: return \"small\"\n",
        "    else: return \"negligible\"\n",
        "\n",
        "print(\"\\n================ Cliff's Delta Effect Sizes ================\")\n",
        "for metric in ['AUC','I','T(α=0.5)']:\n",
        "    print(f\"\\nEffect sizes for {metric}:\")\n",
        "    for m1, m2 in pairs:\n",
        "        x = metrics[metrics['Model']==m1][metric].values\n",
        "        y = metrics[metrics['Model']==m2][metric].values\n",
        "        delta = cliffs_delta(x, y)\n",
        "        print(f\"  {m1} vs {m2}: delta={delta:.4f} ({interpret_delta(delta)})\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 10.5 Bootstrap Confidence Intervals\n",
        "# ------------------------------------------------------------\n",
        "def mean_ci(data, confidence=0.95, n_boot=1000):\n",
        "    if len(data) < 2:\n",
        "        return np.nan, np.nan\n",
        "    res = stats.bootstrap((data,), np.mean, confidence_level=confidence,\n",
        "                          n_resamples=n_boot, random_state=42)\n",
        "    return res.confidence_interval.low, res.confidence_interval.high\n",
        "\n",
        "print(\"\\n================ Bootstrap 95% Confidence Intervals ================\")\n",
        "for metric in ['CV','Jaccard','I','AUC','T(α=0.5)']:\n",
        "    print(f\"\\nBootstrap CI for {metric}:\")\n",
        "    for method in ['SHAP','Banzhaf','Owen']:\n",
        "        data = metrics[metrics['Method']==method][metric].values\n",
        "        low, high = mean_ci(data)\n",
        "        print(f\"  {method}: mean={np.mean(data):.4f} [{low:.4f}, {high:.4f}]\")\n",
        "    overall = metrics[metric].values\n",
        "    low, high = mean_ci(overall)\n",
        "    print(f\"  Overall: mean={np.mean(overall):.4f} [{low:.4f}, {high:.4f}]\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 10.6 Shapiro-Wilk Normality Test\n",
        "# ------------------------------------------------------------\n",
        "print(\"\\n================ Shapiro-Wilk Normality Tests ================\")\n",
        "for metric in ['AUC','I','T(α=0.5)']:\n",
        "    print(f\"\\nNormality for {metric}:\")\n",
        "    for model in ['RF','XGB','LGB']:\n",
        "        data = metrics[metrics['Model']==model][metric].values\n",
        "        stat, p = stats.shapiro(data)\n",
        "        print(f\"  {model}: stat={stat:.4f}, p={p:.4f} ({'normal' if p>0.05 else 'not normal'})\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 10.7 Levene's Test (Equal Variances)\n",
        "# ------------------------------------------------------------\n",
        "print(\"\\n================ Levene's Test for Equal Variances ================\")\n",
        "for metric in ['AUC','I','T(α=0.5)']:\n",
        "    groups = [metrics[metrics['Model']==m][metric].values for m in ['RF','XGB','LGB']]\n",
        "    stat, p = stats.levene(*groups)\n",
        "    print(f\"  {metric}: stat={stat:.2f}, p={p:.4f} ({'equal variances' if p>0.05 else 'unequal variances'})\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 10.8 Spearman Correlation (AUC vs I)\n",
        "# ------------------------------------------------------------\n",
        "print(\"\\n================ Spearman Correlation ================\")\n",
        "rho, p = stats.spearmanr(metrics['AUC'], metrics['I'])\n",
        "print(f\"Overall AUC vs I: rho={rho:.4f}, p={p:.4f}\")\n",
        "\n",
        "for method in ['SHAP','Banzhaf','Owen']:\n",
        "    sub = metrics[metrics['Method']==method]\n",
        "    rho, p = stats.spearmanr(sub['AUC'], sub['I'])\n",
        "    print(f\"  {method}: rho={rho:.4f}, p={p:.4f}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 10.9 Power Analysis\n",
        "# ------------------------------------------------------------\n",
        "print(\"\\n================ Power Analysis ================\")\n",
        "\n",
        "power_analysis = TTestIndPower()\n",
        "alpha = 0.05\n",
        "power = 0.80\n",
        "\n",
        "for effect_size in [0.5, 0.8]:\n",
        "    required_n = power_analysis.solve_power(effect_size=effect_size, alpha=alpha, power=power)\n",
        "    print(f\"\\nEffect size d={effect_size}: required n ≈ {required_n:.1f}\")\n",
        "    print(f\"Your sample size per model: {metrics['Model'].value_counts().iloc[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwNm7AuZsOl1",
        "outputId": "baa91468-d4a9-4dd4-c4e3-18e302b8daeb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ STATISTICAL VALIDATION SUITE (TAIWAN) ================\n",
            "\n",
            "\n",
            "Friedman's Test for Model Comparisons:\n",
            "  AUC: stat=42.75, p=0.0000 (significant)\n",
            "    Kendall's W: 0.8906\n",
            "  I: stat=4.33, p=0.1146 (not significant)\n",
            "    Kendall's W: 0.0903\n",
            "  T(α=0.5): stat=46.08, p=0.0000 (significant)\n",
            "    Kendall's W: 0.9601\n",
            "\n",
            "================ Nemenyi Post-Hoc Tests ================\n",
            "\n",
            "=== Nemenyi Test for AUC ===\n",
            "Mean Ranks: {'RF': np.float64(2.125), 'XGB': np.float64(2.875), 'LGB': np.float64(1.0)}\n",
            "Critical Difference (CD): 0.6764\n",
            "  RF vs XGB: |rank diff|=0.7500 → SIGNIFICANT\n",
            "  RF vs LGB: |rank diff|=1.1250 → SIGNIFICANT\n",
            "  XGB vs LGB: |rank diff|=1.8750 → SIGNIFICANT\n",
            "\n",
            "=== Nemenyi Test for I ===\n",
            "Mean Ranks: {'RF': np.float64(1.9166666666666667), 'XGB': np.float64(2.3333333333333335), 'LGB': np.float64(1.75)}\n",
            "Critical Difference (CD): 0.6764\n",
            "  RF vs XGB: |rank diff|=0.4167 → not significant\n",
            "  RF vs LGB: |rank diff|=0.1667 → not significant\n",
            "  XGB vs LGB: |rank diff|=0.5833 → not significant\n",
            "\n",
            "=== Nemenyi Test for T(α=0.5) ===\n",
            "Mean Ranks: {'RF': np.float64(2.0416666666666665), 'XGB': np.float64(2.9583333333333335), 'LGB': np.float64(1.0)}\n",
            "Critical Difference (CD): 0.6764\n",
            "  RF vs XGB: |rank diff|=0.9167 → SIGNIFICANT\n",
            "  RF vs LGB: |rank diff|=1.0417 → SIGNIFICANT\n",
            "  XGB vs LGB: |rank diff|=1.9583 → SIGNIFICANT\n",
            "\n",
            "================ Wilcoxon Signed-Rank Tests ================\n",
            "\n",
            "Wilcoxon Test for AUC:\n",
            "  RF vs XGB: stat=0.000, p=0.0000\n",
            "  RF vs LGB: stat=6.000, p=0.0000\n",
            "  XGB vs LGB: stat=0.000, p=0.0000\n",
            "\n",
            "Wilcoxon Test for I:\n",
            "  RF vs XGB: stat=78.000, p=0.0395\n",
            "  RF vs LGB: stat=96.000, p=0.1280\n",
            "  XGB vs LGB: stat=149.000, p=0.9888\n",
            "\n",
            "Wilcoxon Test for T(α=0.5):\n",
            "  RF vs XGB: stat=0.000, p=0.0000\n",
            "  RF vs LGB: stat=1.000, p=0.0000\n",
            "  XGB vs LGB: stat=0.000, p=0.0000\n",
            "\n",
            "================ Cliff's Delta Effect Sizes ================\n",
            "\n",
            "Effect sizes for AUC:\n",
            "  RF vs XGB: delta=1.0000 (large)\n",
            "  RF vs LGB: delta=0.4375 (medium)\n",
            "  XGB vs LGB: delta=-0.9688 (large)\n",
            "\n",
            "Effect sizes for I:\n",
            "  RF vs XGB: delta=0.1806 (small)\n",
            "  RF vs LGB: delta=0.0660 (negligible)\n",
            "  XGB vs LGB: delta=0.0035 (negligible)\n",
            "\n",
            "Effect sizes for T(α=0.5):\n",
            "  RF vs XGB: delta=0.8611 (large)\n",
            "  RF vs LGB: delta=0.4028 (medium)\n",
            "  XGB vs LGB: delta=-0.7049 (large)\n",
            "\n",
            "================ Bootstrap 95% Confidence Intervals ================\n",
            "\n",
            "Bootstrap CI for CV:\n",
            "  SHAP: mean=0.6386 [0.6265, 0.6490]\n",
            "  Banzhaf: mean=0.7944 [0.7749, 0.8141]\n",
            "  Owen: mean=0.9733 [0.9556, 0.9941]\n",
            "  Overall: mean=0.8021 [0.7715, 0.8378]\n",
            "\n",
            "Bootstrap CI for Jaccard:\n",
            "  SHAP: mean=0.6859 [0.6495, 0.7289]\n",
            "  Banzhaf: mean=0.4275 [0.3771, 0.4910]\n",
            "  Owen: mean=0.2885 [0.2533, 0.3321]\n",
            "  Overall: mean=0.4673 [0.4221, 0.5151]\n",
            "\n",
            "Bootstrap CI for I:\n",
            "  SHAP: mean=0.5237 [0.5042, 0.5454]\n",
            "  Banzhaf: mean=0.3165 [0.2863, 0.3521]\n",
            "  Owen: mean=0.1576 [0.1408, 0.1803]\n",
            "  Overall: mean=0.3326 [0.2945, 0.3691]\n",
            "\n",
            "Bootstrap CI for AUC:\n",
            "  SHAP: mean=0.7672 [0.7631, 0.7709]\n",
            "  Banzhaf: mean=0.7672 [0.7631, 0.7709]\n",
            "  Owen: mean=0.7672 [0.7631, 0.7709]\n",
            "  Overall: mean=0.7672 [0.7649, 0.7694]\n",
            "\n",
            "Bootstrap CI for T(α=0.5):\n",
            "  SHAP: mean=0.7050 [0.6288, 0.7741]\n",
            "  Banzhaf: mean=0.5094 [0.4461, 0.5574]\n",
            "  Owen: mean=0.3593 [0.2875, 0.4200]\n",
            "  Overall: mean=0.5246 [0.4775, 0.5745]\n",
            "\n",
            "================ Shapiro-Wilk Normality Tests ================\n",
            "\n",
            "Normality for AUC:\n",
            "  RF: stat=0.8895, p=0.0130 (not normal)\n",
            "  XGB: stat=0.9006, p=0.0221 (not normal)\n",
            "  LGB: stat=0.8082, p=0.0004 (not normal)\n",
            "\n",
            "Normality for I:\n",
            "  RF: stat=0.8726, p=0.0059 (not normal)\n",
            "  XGB: stat=0.8624, p=0.0037 (not normal)\n",
            "  LGB: stat=0.9479, p=0.2434 (normal)\n",
            "\n",
            "Normality for T(α=0.5):\n",
            "  RF: stat=0.9211, p=0.0616 (normal)\n",
            "  XGB: stat=0.9660, p=0.5693 (normal)\n",
            "  LGB: stat=0.9380, p=0.1471 (normal)\n",
            "\n",
            "================ Levene's Test for Equal Variances ================\n",
            "  AUC: stat=14.78, p=0.0000 (unequal variances)\n",
            "  I: stat=1.18, p=0.3137 (equal variances)\n",
            "  T(α=0.5): stat=0.69, p=0.5060 (equal variances)\n",
            "\n",
            "================ Spearman Correlation ================\n",
            "Overall AUC vs I: rho=-0.0102, p=0.9320\n",
            "  SHAP: rho=0.4635, p=0.0225\n",
            "  Banzhaf: rho=-0.5017, p=0.0125\n",
            "  Owen: rho=0.0609, p=0.7775\n",
            "\n",
            "================ Power Analysis ================\n",
            "\n",
            "Effect size d=0.5: required n ≈ 63.8\n",
            "Your sample size per model: 24\n",
            "\n",
            "Effect size d=0.8: required n ≈ 25.5\n",
            "Your sample size per model: 24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Model Performance (AUC & T(α=0.5))\n",
        "Across all sampling methods and explanation methods:\n",
        "\n",
        "Best → Worst\n",
        "LightGBM (LGB) — best overall performance\n",
        "\n",
        "Random Forest (RF) — second\n",
        "\n",
        "XGBoost (XGB) — worst\n",
        "\n",
        "This ranking is statistically significant in all tests (Friedman, Nemenyi, Wilcoxon, Cliff’s Delta).\n",
        "\n",
        "2. Interpretability (I)\n",
        "No significant differences between RF, XGB, and LGB.\n",
        "\n",
        "Effect sizes are negligible or small.\n",
        "\n",
        "Interpretability is basically the same across models.\n",
        "\n",
        "3. Explanation Methods\n",
        "SHAP\n",
        "Highest interpretability (I)\n",
        "\n",
        "Highest Jaccard\n",
        "\n",
        "Lowest stability (more variation)\n",
        "\n",
        "Banzhaf\n",
        "Middle ground\n",
        "\n",
        "Moderate interpretability and stability\n",
        "\n",
        "Owen\n",
        "Most stable\n",
        "\n",
        "Lowest interpretability\n",
        "\n",
        "All three explanation methods produce the same AUC, because AUC depends on the model, not the explainer.\n",
        "\n",
        "4. Sampling Methods\n",
        "Across RF, XGB, and LGB:\n",
        "\n",
        "None, Under-sampling, and CostSensitive tend to give the best AUC.\n",
        "\n",
        "SMOTE, Borderline, ADASYN slightly reduce AUC for all models.\n",
        "\n",
        "SMOTEENN / SMOTETomek are mixed but never outperform the best methods.\n",
        "\n",
        "Conclusion:  \n",
        "Oversampling does not improve performance on this dataset.\n",
        "\n",
        "1. Friedman Tests (Overall Model Differences)\n",
        "AUC: Significant differences between models (p < 0.0001).\n",
        "\n",
        "T(α=0.5): Significant differences (p < 0.0001).\n",
        "\n",
        "I (Interpretability Index): No significant differences (p = 0.1146).\n",
        "\n",
        "Interpretation:  \n",
        "Models differ strongly in predictive performance (AUC, T), but not in interpretability (I).\n",
        "\n",
        "2. Nemenyi Post‑Hoc Tests (Pairwise Model Ranking)\n",
        "AUC Ranking:\n",
        "LGB (best)\n",
        "\n",
        "RF\n",
        "\n",
        "XGB (worst)\n",
        "\n",
        "All pairwise differences are significant.\n",
        "\n",
        "I (Interpretability):\n",
        "No significant differences between any models.\n",
        "\n",
        "T(α=0.5):\n",
        "Same pattern as AUC:\n",
        "\n",
        "LGB > RF > XGB, all significant.\n",
        "\n",
        "3. Wilcoxon Signed‑Rank Tests (Pairwise Performance)\n",
        "AUC:\n",
        "All comparisons significant (p = 0.0000).\n",
        "→ Confirms LGB > RF > XGB.\n",
        "\n",
        "I:\n",
        "RF vs XGB: small but significant difference.\n",
        "\n",
        "RF vs LGB: not significant.\n",
        "\n",
        "XGB vs LGB: not significant.\n",
        "→ Interpretability is similar across models.\n",
        "\n",
        "T(α=0.5):\n",
        "All comparisons significant.\n",
        "→ Again LGB > RF > XGB.\n",
        "\n",
        "4. Cliff’s Delta (Effect Sizes)\n",
        "AUC:\n",
        "RF vs XGB: large\n",
        "\n",
        "RF vs LGB: medium\n",
        "\n",
        "XGB vs LGB: large\n",
        "\n",
        "→ Strong practical differences in performance.\n",
        "\n",
        "I:\n",
        "All effect sizes are small or negligible.\n",
        "→ Interpretability is similar.\n",
        "\n",
        "T(α=0.5):\n",
        "Large effects again confirm LGB > RF > XGB.\n",
        "\n",
        "5. Bootstrap Confidence Intervals\n",
        "AUC:\n",
        "All methods have identical mean AUC (0.7672) because AUC is averaged across explanation methods.\n",
        "→ Confirms stability of AUC estimates.\n",
        "\n",
        "Interpretability (I):\n",
        "SHAP highest (best interpretability)\n",
        "\n",
        "Banzhaf moderate\n",
        "\n",
        "Owen lowest\n",
        "\n",
        "Stability (CV):\n",
        "Owen most stable\n",
        "\n",
        "SHAP least stable\n",
        "\n",
        "6. Normality & Variance Tests\n",
        "AUC is not normally distributed and has unequal variances → non‑parametric tests were appropriate.\n",
        "\n",
        "I and T are mostly normal with equal variances.\n",
        "\n",
        "7. Spearman Correlation\n",
        "Overall AUC vs I: no correlation (ρ ≈ 0).\n",
        "\n",
        "SHAP: moderate positive correlation.\n",
        "\n",
        "Banzhaf: moderate negative correlation.\n",
        "\n",
        "Owen: no correlation.\n",
        "\n",
        "Interpretation:  \n",
        "Interpretability scores do not predict model performance.\n",
        "\n",
        "8. Power Analysis\n",
        "For medium effect (d = 0.5), required n ≈ 64 → your n = 24 is underpowered.\n",
        "\n",
        "For large effect (d = 0.8), required n ≈ 26 → your n = 24 is borderline.\n",
        "\n",
        "Interpretation:  \n",
        "Large effects are detected reliably; small effects may be missed.\n",
        "\n",
        "Final Conclusions\n",
        "LightGBM is the best-performing model across AUC and T(α=0.5), significantly outperforming both RF and XGB.\n",
        "\n",
        "Random Forest is the second-best, consistently better than XGB.\n",
        "\n",
        "XGBoost performs the worst across all predictive metrics.\n",
        "\n",
        "Interpretability (I) does not differ significantly between models, and effect sizes are negligible.\n",
        "\n",
        "SHAP provides the highest interpretability, but with lower stability; Owen is most stable but least interpretable.\n",
        "\n",
        "All statistical tests (Friedman, Nemenyi, Wilcoxon, Cliff’s Delta) consistently confirm the ranking:\n",
        "LGB > RF > XGB.\n",
        "\n",
        "Bootstrap CIs show stable estimates, and power analysis indicates the study is well-powered for large effects."
      ],
      "metadata": {
        "id": "6vvMcliB-fL_"
      }
    }
  ]
}