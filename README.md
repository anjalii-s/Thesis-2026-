1. Data Loading & Preprocessing
Load German Credit dataset.

Apply OneHotEncoder for categorical features and StandardScaler for numeric features.

2. Model & Sampler Setup
Define models: Random Forest (RF), XGBoost (XGB), LightGBM (LGB).

Define imbalance handling: None, SMOTE, Borderline, ADASYN, SMOTEENN, SMOTETomek, Under, CostSensitive.

3. Training Loop
Train all model Ã— sampler combinations across multiple seeds.

Collect AUC scores.

4. Explanation Methods
Implement SHAP (TreeExplainer).

Implement Banzhaf approximation (coalition sampling).

Implement Owen values (groupâ€‘aware coalitions).

5. Metrics Functions
Stability (CV).

Jaccard similarity of topâ€‘k features.

Interpretability score 
ğ¼
=
ğ›½
(
1
âˆ’
ğ¶
ğ‘‰
)
+
(
1
âˆ’
ğ›½
)
ğ½
.

Tradeâ€‘off score 
ğ‘‡
(
ğ›¼
)
=
ğ›¼
â‹…
ğ´
ğ‘ˆ
ğ¶
+
(
1
âˆ’
ğ›¼
)
â‹…
ğ¼
.

6. Collect Explanations
For each configuration, compute SHAP, Banzhaf, Owen explanations on subsampled test sets.

7. Compute Metrics
Aggregate AUC, CV, Jaccard, I, and T across seeds.

Store results in metrics_methods.

8. Plots
Average tradeâ€‘off by method.

Accuracy vs interpretability scatter.

Top configurations per method.

9. LaTeX Export
Export perâ€‘method tables.

Export summary averages.
